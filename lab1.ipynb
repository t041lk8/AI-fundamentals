{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1 \"Градиентный спуск и его модификации\"\n",
    "\n",
    "## Задание\n",
    "\n",
    "1. Градиентный спуск и его модификации\n",
    "   - Выбрать [тестовые функции оптимизации](https://ru.wikipedia.org/wiki/Тестовые_функции_для_оптимизации) (2 шт)\n",
    "   - Запрограммировать собственную реализацию классического градиентного спуска\n",
    "   - Запрограммировать пайлайн тестирования алгоритма оптимизации\n",
    "     - Визуализации функции и точки оптимума\n",
    "     - Вычисление погрешности найденного решения в сравнение с аналитическим для нескольких запусков\n",
    "     - Визуализации точки найденного решения (можно добавить анимацию на плюс балл)\n",
    "   - Запрограммировать метод вычисления градиента\n",
    "     - Передача функции градиента от пользователя\n",
    "     - Символьное вычисление градиента (например с помощью [sympy](https://www.sympy.org/en/index.html)) (на доп балл)\n",
    "     - Численная аппроксимация градиента (на доп балл)\n",
    "   - Запрограммировать одну моментную модификацию и протестировать ее\n",
    "   - Запрограммировать одну адаптивную модификацию и протестировать ее\n",
    "   - Запрограммировать метод эфолюции темпа обучения и/или метод выбора начального приближения и протестировать их\n",
    "   - `Will be unclocked afetr Lecture №5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение\n",
    "\n",
    "В качестве тестовых функций возьмем: \n",
    "- **функция Розенброка** \n",
    "\n",
    "1. $ f(x) = \\sum _ {i=1} ^ {n-1} [100(x_{i+1}-x_{i}^{2})^2+(x_i-1)^2]$\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Rosenbrock%27s_function_in_3D.pdf/page1-640px-Rosenbrock%27s_function_in_3D.pdf.jpg?uselang=ru)\n",
    "\n",
    "2. Минимум: $ f(1_0, 1_1, ..., 1_n)=0 $\n",
    "\n",
    "3. Метод поиска: $-\\infty \\leq x_i \\leq \\infty, 1 \\leq i \\leq n$\n",
    "\n",
    "- **функция Била**\n",
    "\n",
    "1. $ f(x,y) = (1.5-x+xy)^2+(2.25-x+xy^2)^2+(2.625-x+xy^3)^2 $\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Beale%27s_function.pdf/page1-640px-Beale%27s_function.pdf.jpg?uselang=ru)\n",
    "\n",
    "2. Минимум: $ f(3, 0.5) = 0 $\n",
    "\n",
    "3. Метод поиска: $-4.5 \\leq x,y \\leq 4.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем вычисление выбранных тестовых функций. Для функции Розенброка реализуем вариант функции от двух переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(point):\n",
    "    x, y = point[0], point[1]\n",
    "    return 100 * (y - x**2)**2 + (x - 1)**2\n",
    "\n",
    "def beale(point):\n",
    "    x, y = point[0], point[1]\n",
    "    return ((1.5 - x + x * y)**2 +\n",
    "            (2.25 - x + x * y**2)**2 +\n",
    "            (2.625 - x + x * y**3)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем классический алгоритм градиентного спуска. На данном этапе будем подавать при вызове функцию для подсчета градиента. Позже, после выполнения задания по численной аппроксимации, сосздадим еще одну имплементацию, которая уже будет использовать приблежнные значения градиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent:\n",
    "    def __init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n",
    "        \"\"\"\n",
    "        Конструктор класса GradientDescent.\n",
    "\n",
    "        :param learning_rate: Скорость обучения (шаг градиентного спуска).\n",
    "        :param max_iterations: Максимальное количество итераций.\n",
    "        :param tolerance: Критерий остановки, если изменения функции невелики.\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.tolerance = tolerance\n",
    "        self.path = []  # Для сохранения траектории точек\n",
    "\n",
    "    def minimize(self, func, grad_func, initial_point):\n",
    "        \"\"\"\n",
    "        Метод для минимизации функции с использованием градиентного спуска.\n",
    "\n",
    "        :param func: Целевая функция, которую нужно минимизировать.\n",
    "        :param grad_func: Градиент целевой функции.\n",
    "        :param initial_point: Начальная точка для поиска минимума.\n",
    "        :return: Кортеж (минимальное значение функции, точка минимума, путь градиента).\n",
    "        \"\"\"\n",
    "        point = np.array(initial_point)\n",
    "        self.path = [point.copy()]  # Сохраняем начальную точку\n",
    "\n",
    "        for i in range(self.max_iterations):\n",
    "            gradient = np.array(grad_func(point))\n",
    "            new_point = point - self.learning_rate * gradient\n",
    "\n",
    "            # Проверка критерия остановки\n",
    "            if np.linalg.norm(new_point - point) < self.tolerance:\n",
    "                print(f\"Сошлось за {i+1} итераций.\")\n",
    "                self.path.append(new_point.copy())\n",
    "                return func(new_point), new_point, self.path\n",
    "\n",
    "            point = new_point\n",
    "            self.path.append(point.copy())  # Сохраняем текущую точку\n",
    "\n",
    "        print(\"Достигнуто максимальное количество итераций.\")\n",
    "        return func(point), point, self.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем пайплайн визуализации и подсчета ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_optimization_plotly(function, x_min, y_min, optimization_paths):\n",
    "    \"\"\"\n",
    "    Визуализирует функцию, точку минимума и пути оптимизации в 3D с использованием Plotly.\n",
    "\n",
    "    :param function: Целевая функция.\n",
    "    :param x_min: Реальная x-координата минимума.\n",
    "    :param y_min: Реальная y-координата минимума.\n",
    "    :param optimization_paths: Список путей градиентного спуска. Каждый путь — это массив точек [(x1, y1), ..., (xn, yn)].\n",
    "    \"\"\"\n",
    "    # Создание сетки для 3D-графика\n",
    "    x = np.linspace(-2, 2, 100)\n",
    "    y = np.linspace(-1, 3, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = function(X, Y)\n",
    "\n",
    "    # 3D поверхность функции\n",
    "    surface = go.Surface(z=Z, x=X, y=Y, colorscale='Viridis', opacity=0.8)\n",
    "\n",
    "    # Точка минимума\n",
    "    minimum_point = go.Scatter3d(\n",
    "        x=[x_min],\n",
    "        y=[y_min],\n",
    "        z=[function(x_min, y_min)],\n",
    "        mode='markers',\n",
    "        marker=dict(size=6, color='red'),\n",
    "        name='Точка минимума'\n",
    "    )\n",
    "\n",
    "    # Пути оптимизации\n",
    "    paths = []\n",
    "    for idx, path in enumerate(optimization_paths):\n",
    "        xs, ys = zip(*path)\n",
    "        zs = [function(x, y) for x, y in path]\n",
    "        paths.append(\n",
    "            go.Scatter3d(\n",
    "                x=xs,\n",
    "                y=ys,\n",
    "                z=zs,\n",
    "                mode='lines+markers',\n",
    "                name=f'Путь {idx + 1}'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Настройка графика\n",
    "    fig = go.Figure(data=[surface, minimum_point] + paths)\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='X',\n",
    "            yaxis_title='Y',\n",
    "            zaxis_title='f(X, Y)',\n",
    "        ),\n",
    "        title=\"3D-визуализация функции и пути оптимизации\",\n",
    "        margin=dict(l=0, r=0, b=0, t=40)\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def calculate_errors(function, x_min, y_min, optimization_paths):\n",
    "    \"\"\"\n",
    "    Вычисляет погрешности по модулю для каждого прогона и среднюю погрешность.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for path in optimization_paths:\n",
    "        x_opt, y_opt = path[-1]  # Последняя точка пути — точка завершения\n",
    "        error = np.sqrt((x_opt - x_min)**2 + (y_opt - y_min)**2)\n",
    "        errors.append(error)\n",
    "\n",
    "    mean_error = np.mean(errors)\n",
    "\n",
    "    print(\"Погрешности по каждому прогону:\")\n",
    "    for i, error in enumerate(errors, 1):\n",
    "        print(f\"Прогон {i}: Погрешность = {error:.6f}\")\n",
    "\n",
    "    print(f\"\\nСредняя погрешность: {mean_error:.6f}\")\n",
    "\n",
    "    return errors, mean_error\n",
    "\n",
    "\n",
    "def pipeline(function, x_min, y_min, optimization_paths):\n",
    "    # Визуализация\n",
    "    visualize_optimization_plotly(function, x_min, x_min, optimization_paths)\n",
    "\n",
    "    # Вычисление погрешностей\n",
    "    calculate_errors(function, x_min, x_min, optimization_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку метод градиентного спуска реализован пока что через подсчет по готовой функции градиента, воспользуемся библиотекой sympy для нахождения функции градиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(func):\n",
    "    # Запрос функции от пользователя\n",
    "    expr_str = func\n",
    "    \n",
    "    # Парсим введенную строку как выражение sympy\n",
    "    expr = sp.sympify(expr_str)\n",
    "    \n",
    "    # Определяем переменные\n",
    "    variables = list(expr.free_symbols)  # Автоматически находим все переменные\n",
    "    \n",
    "    # Вычисляем градиент\n",
    "    gradient = [sp.diff(expr, var) for var in variables]\n",
    "    \n",
    "    # Вывод результата\n",
    "    for var, partial_derivative in zip(variables, gradient):\n",
    "        print(f\"∂/∂{var}: {partial_derivative}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Градиент функции Розенброка:\n",
      "∂/∂x: -400*x*(-x**2 + y) + 2*x - 2\n",
      "∂/∂y: -200*x**2 + 200*y\n",
      "Градиент функции Била:\n",
      "∂/∂x: 2.25*(1.33333333333333*y - 1.33333333333333)*(0.666666666666667*x*y - 0.666666666666667*x + 1) + 5.0625*(0.888888888888889*y**2 - 0.888888888888889)*(0.444444444444444*x*y**2 - 0.444444444444444*x + 1) + 6.890625*(0.761904761904762*y**3 - 0.761904761904762)*(0.380952380952381*x*y**3 - 0.380952380952381*x + 1)\n",
      "∂/∂y: 15.75*x*y**2*(0.380952380952381*x*y**3 - 0.380952380952381*x + 1) + 9.0*x*y*(0.444444444444444*x*y**2 - 0.444444444444444*x + 1) + 3.0*x*(0.666666666666667*x*y - 0.666666666666667*x + 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Градиент функции Розенброка:\")\n",
    "compute_gradient('100 * (y - x**2)**2 + (x - 1)**2')\n",
    "print(\"Градиент функции Била:\")\n",
    "compute_gradient('((1.5 - x + x * y)**2 + (2.25 - x + x * y**2)**2 + (2.625 - x + x * y**3)**2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем полученные градиенты в функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock_grad(point):\n",
    "    x, y = point[0], point[1]\n",
    "    return np.array([-400*x*(-x**2 + y) + 2*x - 2, -200*x**2 + 200*y]) \n",
    "\n",
    "def beale_grad(point):\n",
    "    x, y = point[0], point[1]\n",
    "    return np.array([2.25*(1.33333333333333*y - 1.33333333333333)*(0.666666666666667*x*y - 0.666666666666667*x + 1) + 5.0625*(0.888888888888889*y**2 - 0.888888888888889)*(0.444444444444444*x*y**2 - 0.444444444444444*x + 1) + 6.890625*(0.761904761904762*y**3 - 0.761904761904762)*(0.380952380952381*x*y**3 - 0.380952380952381*x + 1), 15.75*x*y**2*(0.380952380952381*x*y**3 - 0.380952380952381*x + 1) + 9.0*x*y*(0.444444444444444*x*y**2 - 0.444444444444444*x + 1) + 3.0*x*(0.666666666666667*x*y - 0.666666666666667*x + 1)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подсчитаем минимумы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosenbrock_gradient_descent = GradientDescent()\n",
    "beale_gradient_descent = GradientDescent()\n",
    "\n",
    "res = rosenbrock_gradient_descent.minimize(rosenbrock, rosenbrock_grad, (-3, -3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def rosenbrock_2d(x, y):\n",
    "    \"\"\"\n",
    "    Функция Розенброка для двух переменных.\n",
    "    \"\"\"\n",
    "    return 100 * (y - x**2)**2 + (x - 1)**2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    # Реальная точка минимума\n",
    "    x_min_real, y_min_real = 1, 1\n",
    "\n",
    "    # Пути оптимизации (пример)\n",
    "    optimization_paths = [\n",
    "        [(0, 0), (0.5, 0.2), (0.8, 0.5), (1.0, 0.8), (1.0, 1.0)],\n",
    "        [(0, 0), (0.6, 0.3), (0.9, 0.7), (1.0, 1.0)],\n",
    "        [(0, 0), (0.4, 0.1), (0.7, 0.4), (0.9, 0.9), (1.0, 1.0)]\n",
    "    ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Градиент функции:\n",
      "∂/∂x: 6.0*x - 2.0*xy**3 - 2.0*xy**2 - 2.0*xy - 12.75\n",
      "∂/∂xy: -2.0*x + 15.75*xy**2*(-0.380952380952381*x + 0.380952380952381*xy**3 + 1) + 9.0*xy*(-0.444444444444444*x + 0.444444444444444*xy**2 + 1) + 2.0*xy + 3.0\n"
     ]
    }
   ],
   "source": [
    "compute_gradient('(1.5-x+xy)^2+(2.25-x+xy^2)^2+(2.625-x+xy^3)^2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
